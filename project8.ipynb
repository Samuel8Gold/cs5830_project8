{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c374e20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import random\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import SVG\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from graphviz import Source\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52877321",
   "metadata": {},
   "source": [
    "Link to the dataset: https://www.kaggle.com/datasets/janiobachmann/bank-marketing-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c685e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"bank.csv\")\n",
    "df['deposit'] = df['deposit'].map({'no': 0, 'yes': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ff47d9",
   "metadata": {},
   "source": [
    "## Is there something wrong with Month??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88165c5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "months = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "for month in months:\n",
    "    df['month_' + month] = df['month'].apply(lambda x: 1 if x.lower() == month else 0)\n",
    "df.drop(columns=[\"month\"], inplace=True)\n",
    "for val in df[\"month_mar\"].unique():\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88ca416",
   "metadata": {},
   "source": [
    "## Handle Binary Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992225c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['default'] = df['default'].map({'no': 0, 'yes': 1})\n",
    "df['housing'] = df['housing'].map({'no': 0, 'yes': 1})\n",
    "df['loan'] = df['loan'].map({'no': 0, 'yes': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b464c9d8",
   "metadata": {},
   "source": [
    "## One Hot Encode and Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8a6d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('deposit', axis=1)\n",
    "y = df['deposit'] \n",
    "\n",
    "display(X.columns)\n",
    "display(X.head())\n",
    "\n",
    "X = pd.get_dummies(X, dtype=int)\n",
    "\n",
    "# campaign is a categorical variable, so we need to perform one-hot encoding on it\n",
    "campaign = pd.get_dummies(X.campaign, prefix='campaign', dtype=int)\n",
    "dropped = X.drop('campaign', axis=1)\n",
    "\n",
    "# combine the one-hot encoded campaign with the original features\n",
    "X = pd.concat([dropped, campaign], axis=1)\n",
    "continuous_features = X[['age','balance', 'day', 'duration', 'pdays']]\n",
    "\n",
    "for column in continuous_features:\n",
    "    X[column] = (X[column] - X[column].mean()) / X[column].std()\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe608e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1057be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997e56d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "treeclf = DecisionTreeClassifier(max_depth=3, random_state=1)\n",
    "treeclf.fit(X.values, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ea3039",
   "metadata": {},
   "outputs": [],
   "source": [
    "classNames = y.unique().astype(str)\n",
    "dot = tree.export_graphviz(treeclf, out_file=None,\n",
    "                           feature_names=X.columns,\n",
    "                           class_names=classNames, \n",
    "                           filled = True)\n",
    "# display the graph here\n",
    "graph = Source(dot)\n",
    "svg = SVG(graph.pipe(format='svg'))\n",
    "display(svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a55152",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "treeclf = DecisionTreeClassifier(max_depth=2, random_state=1)\n",
    "treeclf.fit(X.values, y)\n",
    "classNames = y.unique().astype(str)\n",
    "dot = tree.export_graphviz(treeclf, out_file=None,\n",
    "                           feature_names=X.columns,\n",
    "                           class_names=classNames, \n",
    "                           filled = True)\n",
    "# display the graph here\n",
    "graph = Source(dot)\n",
    "svg = SVG(graph.pipe(format='svg'))\n",
    "display(svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c63f386",
   "metadata": {},
   "outputs": [],
   "source": [
    "treeclf = DecisionTreeClassifier(max_depth=4, random_state=1)\n",
    "treeclf.fit(X.values, y)\n",
    "classNames = y.unique().astype(str)\n",
    "dot = tree.export_graphviz(treeclf, out_file=None,\n",
    "                           feature_names=X.columns,\n",
    "                           class_names=classNames, \n",
    "                           filled = True)\n",
    "# display the graph here\n",
    "graph = Source(dot)\n",
    "svg = SVG(graph.pipe(format='svg'))\n",
    "display(svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff320fa",
   "metadata": {},
   "source": [
    "## Visualize the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b8b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = 'deposit'\n",
    "for feature in continuous_features:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(X[feature], y, alpha=0.5)\n",
    "    plt.title(f'Scatter Plot of {feature} vs {target_variable}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(target_variable)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1abc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([X, y], axis=1)\n",
    "corr_matrix = df.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", annot_kws={\"size\": 10})\n",
    "plt.title('Correlation Heatmap of All Columns In Dataframe')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47cb32d",
   "metadata": {},
   "source": [
    "## Remove lots of features that aren't in the decision tree to help when I want to regraph the heatmap since the above graph is unreadable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d2ee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_columns = df.filter(regex='^campaign_', axis=1).columns\n",
    "df = df.drop(campaign_columns, axis=1)\n",
    "job_columns = df.filter(regex='^job_', axis=1).columns\n",
    "df = df.drop(job_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29334d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", annot_kws={\"size\": 10})\n",
    "plt.title('Correlation Heatmap of All Columns In Dataframe')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d057fdd2",
   "metadata": {},
   "source": [
    "## Make a Heatmap of just the months compared with the target variable since tyhe above heatmaps were clearly too complicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e3522",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_columns = df.filter(regex='^month_', axis=1).columns\n",
    "heatmap_df = df[['deposit'] + list(month_columns)]\n",
    "correlation_matrix = heatmap_df.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap of \"deposit\" and \"month_\" Columns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e38d81c",
   "metadata": {},
   "source": [
    "## Visualize Heapmap without The Month Correlations With Deposit because we don't want it to be understandable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5877f408",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_columns = df.filter(regex='^month_', axis=1).columns\n",
    "df = df.drop(month_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1d2824",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df.corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", annot_kws={\"size\": 10})\n",
    "plt.title('Correlation Heatmap of All Columns In Dataframe')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8116f0",
   "metadata": {},
   "source": [
    "## Make a heatmap to show the different continuous features coorelations to the target variable since heatmapping too many variable again failed miserably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5bbea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df[['age', 'balance', 'day', 'duration', 'pdays', 'deposit']].corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", annot_kws={\"size\": 10})\n",
    "plt.title('Correlation Heatmap of All Columns In Dataframe')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214eb841",
   "metadata": {},
   "source": [
    "Duration: Duration of the last contact to the potential person who will make a deposit in the bank..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb4a410",
   "metadata": {},
   "source": [
    "## Make A decision tree with just duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05e2b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "treeclf = DecisionTreeClassifier(max_depth=2, random_state=1)\n",
    "treeclf.fit(X[[\"duration\"]].values, y)\n",
    "classNames = y.unique().astype(str)\n",
    "dot = tree.export_graphviz(treeclf, out_file=None,\n",
    "                           feature_names=X[[\"duration\"]].columns,\n",
    "                           class_names=classNames, \n",
    "                           filled = True)\n",
    "# display the graph here\n",
    "graph = Source(dot)\n",
    "svg = SVG(graph.pipe(format='svg'))\n",
    "display(svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb46e9aa",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca62ed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"bank.csv\")\n",
    "df['deposit'] = df['deposit'].map({'no': 0, 'yes': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88213c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('deposit', axis=1)  # Drop the target variable to get the features\n",
    "y = df['deposit']  # Select only the target variable\n",
    "\n",
    "# Display the original DataFrame\n",
    "# print(\"Original DataFrame:\")\n",
    "# print(df.head())\n",
    "display(X.columns)\n",
    "display(X.head())\n",
    "\n",
    "\n",
    "\n",
    "# Perform one-hot encoding on the features\n",
    "X = pd.get_dummies(X, dtype=int)\n",
    "X = X.drop('campaign', axis=1)\n",
    "\n",
    "# uncomment this code if you want to try encoding with the campaign\n",
    "# # campaign is a categorical variable, so we need to perform one-hot encoding on it\n",
    "# campaign = pd.get_dummies(X.campaign, prefix='campaign', dtype=int)\n",
    "# dropped = X.drop('campaign', axis=1)\n",
    "\n",
    "# # combine the one-hot encoded campaign with the original features\n",
    "# X = pd.concat([dropped, campaign], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "continuous_features = X[['age','balance', 'day', 'duration', 'pdays']]\n",
    "\n",
    "for column in continuous_features:\n",
    "    X[column] = (X[column] - X[column].mean()) / X[column].std()\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd879f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10),max_iter=500) # 1 layer, 5 nodes\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "predictions = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff1b5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1fde4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This dataset has {} input nodes and {} output node(s)'.format(len(X.columns), len(y.unique())))\n",
    "print('There are {} 2D arrays of coefficients, one for each layer'.format(len(mlp.coefs_)))\n",
    "print('The layers have the following number of coefficients: {}')\n",
    "for l in range(len(mlp.coefs_)):\n",
    "    m = len(mlp.coefs_[l])\n",
    "    n = len(mlp.coefs_[l][0])\n",
    "    print('  {}: {}x{} ({} nodes feeding into a layer of {} nodes)'.format(l, m, n, m, n))\n",
    "# Print the actual coefficients\n",
    "# print(mlp.coefs_)\n",
    "\n",
    "print()\n",
    "print('There are {} 1D arrays of intercepts, one for each layer'.format(len(mlp.intercepts_)))\n",
    "print('Each layer has {} intercepts, one for each node'.format([len(mlp.intercepts_[l]) for l,_ in enumerate(mlp.intercepts_)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ed4b378",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_AxesStack' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 50>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m     weights \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mabs\u001b[39m(G[u][v][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m u,v \u001b[38;5;129;01min\u001b[39;00m edges]\n\u001b[0;32m     48\u001b[0m     nx\u001b[38;5;241m.\u001b[39mdraw(G, pos, node_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, node_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m450\u001b[39m, width\u001b[38;5;241m=\u001b[39mweights, edge_color\u001b[38;5;241m=\u001b[39mcolors)\n\u001b[1;32m---> 50\u001b[0m \u001b[43mshow_ann\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36mshow_ann\u001b[1;34m(mlp)\u001b[0m\n\u001b[0;32m     43\u001b[0m colors \u001b[38;5;241m=\u001b[39m [colorsys\u001b[38;5;241m.\u001b[39mhsv_to_rgb(\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m G[u][v][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.65\u001b[39m,\n\u001b[0;32m     44\u001b[0m                               \u001b[38;5;241m1\u001b[39m,\u001b[38;5;66;03m#min(1, abs(G[u][v]['weight'])),\u001b[39;00m\n\u001b[0;32m     45\u001b[0m                               \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m u,v \u001b[38;5;129;01min\u001b[39;00m edges]\n\u001b[0;32m     46\u001b[0m weights \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mabs\u001b[39m(G[u][v][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m u,v \u001b[38;5;129;01min\u001b[39;00m edges]\n\u001b[1;32m---> 48\u001b[0m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m450\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py:112\u001b[0m, in \u001b[0;36mdraw\u001b[1;34m(G, pos, ax, **kwds)\u001b[0m\n\u001b[0;32m    110\u001b[0m cf\u001b[38;5;241m.\u001b[39mset_facecolor(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_axstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    113\u001b[0m         ax \u001b[38;5;241m=\u001b[39m cf\u001b[38;5;241m.\u001b[39madd_axes((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: '_AxesStack' object is not callable"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# you may need to install networkx with pip\n",
    "import networkx as nx\n",
    "import colorsys\n",
    "\n",
    "def show_ann(mlp):\n",
    "    hidden_layers_n = len(mlp.coefs_)-1\n",
    "    layers_n = hidden_layers_n + 2\n",
    "    input_neurons_n = len(mlp.coefs_[0])\n",
    "    hidden_neurons_n = [len(mlp.coefs_[i+1]) for i in range(hidden_layers_n)]\n",
    "    output_neurons_n = len(mlp.coefs_[-1][0])\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "    pos = {}\n",
    "\n",
    "    # Create the neurons of the input layer\n",
    "    for i in range(input_neurons_n):\n",
    "        pos['Layer0_{}'.format(i)] = (i,layers_n-1)\n",
    "\n",
    "    for j in range(hidden_layers_n):\n",
    "        # Create the neurons of the j'th hidden layer\n",
    "        prev_layer = j\n",
    "        cur_layer = j+1\n",
    "        if (j == 0):\n",
    "            prev_size = input_neurons_n\n",
    "        else:\n",
    "            prev_size = hidden_neurons_n[j-1]\n",
    "        for i in range(hidden_neurons_n[j]):\n",
    "            pos['Layer{}_{}'.format(cur_layer,i)] = (i,layers_n-1-cur_layer)\n",
    "            for k in range(prev_size):\n",
    "                w = mlp.coefs_[prev_layer][k][i]\n",
    "                G.add_edge('Layer{}_{}'.format(prev_layer,k),'Layer{}_{}'.format(cur_layer,i), weight=w)\n",
    "\n",
    "    # Create the neurons of the output layer\n",
    "    prev_layer = hidden_layers_n\n",
    "    cur_layer = hidden_layers_n+1\n",
    "    for i in range(output_neurons_n):\n",
    "        pos['Layer{}_{}'.format(cur_layer,i)] = (i,layers_n-1-cur_layer)\n",
    "        for k in range(hidden_neurons_n[-1]):\n",
    "            w = mlp.coefs_[prev_layer][k][i]\n",
    "            G.add_edge('Layer{}_{}'.format(prev_layer,k),'Layer{}_{}'.format(cur_layer,i), weight=w)\n",
    "\n",
    "    edges = G.edges()\n",
    "    colors = [colorsys.hsv_to_rgb(0 if G[u][v]['weight'] < 0 else 0.65,\n",
    "                                  1,#min(1, abs(G[u][v]['weight'])),\n",
    "                                  1) for u,v in edges]\n",
    "    weights = [abs(G[u][v]['weight'])*2 for u,v in edges]\n",
    "\n",
    "    nx.draw(G, pos, node_color='y', node_size=450, width=weights, edge_color=colors)\n",
    "    \n",
    "show_ann(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c569b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 10),max_iter=500) # 1 layer, 5 nodes\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "predictions = mlp.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884cc163",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This dataset has {} input nodes and {} output node(s)'.format(len(X.columns), len(y.unique())))\n",
    "print('There are {} 2D arrays of coefficients, one for each layer'.format(len(mlp.coefs_)))\n",
    "print('The layers have the following number of coefficients: {}')\n",
    "for l in range(len(mlp.coefs_)):\n",
    "    m = len(mlp.coefs_[l])\n",
    "    n = len(mlp.coefs_[l][0])\n",
    "    print('  {}: {}x{} ({} nodes feeding into a layer of {} nodes)'.format(l, m, n, m, n))\n",
    "# Print the actual coefficients\n",
    "# print(mlp.coefs_)\n",
    "\n",
    "print()\n",
    "print('There are {} 1D arrays of intercepts, one for each layer'.format(len(mlp.intercepts_)))\n",
    "print('Each layer has {} intercepts, one for each node'.format([len(mlp.intercepts_[l]) for l,_ in enumerate(mlp.intercepts_)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3be7484",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_ann(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd3782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(20, 10, 5),max_iter=500) # 1 layer, 5 nodes\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "predictions = mlp.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728cc0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This dataset has {} input nodes and {} output node(s)'.format(len(X.columns), len(y.unique())))\n",
    "print('There are {} 2D arrays of coefficients, one for each layer'.format(len(mlp.coefs_)))\n",
    "print('The layers have the following number of coefficients: {}')\n",
    "for l in range(len(mlp.coefs_)):\n",
    "    m = len(mlp.coefs_[l])\n",
    "    n = len(mlp.coefs_[l][0])\n",
    "    print('  {}: {}x{} ({} nodes feeding into a layer of {} nodes)'.format(l, m, n, m, n))\n",
    "# Print the actual coefficients\n",
    "# print(mlp.coefs_)\n",
    "\n",
    "print()\n",
    "print('There are {} 1D arrays of intercepts, one for each layer'.format(len(mlp.intercepts_)))\n",
    "print('Each layer has {} intercepts, one for each node'.format([len(mlp.intercepts_[l]) for l,_ in enumerate(mlp.intercepts_)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9175780",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_ann(mlp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
